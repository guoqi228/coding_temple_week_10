{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example for Pos_Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "uc1 = \"The University of Chicago is a private research university in Chicago, Illinois\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('University', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Chicago', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('private', 'JJ'),\n",
       " ('research', 'NN'),\n",
       " ('university', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('Chicago', 'NNP'),\n",
       " (',', ','),\n",
       " ('Illinois', 'NNP')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.tokenize.word_tokenize(uc1)\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('NNP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get raw text from a url, and do nlp\n",
    "- Preprocessing\n",
    "- Get token Frq\n",
    "- Get bigram Frq\n",
    "- Get trigram Frq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.zhaimobile.com\"\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "page = urllib.request.urlopen(url)\n",
    "soup = BeautifulSoup(page.read(), \"lxml\")\n",
    "raw = (soup.get_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_words = nltk.word_tokenize(raw)\n",
    "# Clean words\n",
    "words = [word for word in raw_words if len(word) > 1]\n",
    "words = [word for word in words if word.isalpha()]\n",
    "words = [w.lower() for w in words if w.isalnum()]\n",
    "# Stop words\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "words = [word for word in words if word not in stopwords]\n",
    "# Lemma or Stem; use Lemmatizer for better results\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "cleaned_words = [wnl.lemmatize(t) for t in words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('development', 8),\n",
       " ('data', 6),\n",
       " ('web', 6),\n",
       " ('skill', 6),\n",
       " ('game', 6),\n",
       " ('mo', 5),\n",
       " ('zhai', 5),\n",
       " ('science', 5),\n",
       " ('software', 5),\n",
       " ('solid', 5)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(cleaned_words)\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('mo', 'zhai'), 3),\n",
       " (('data', 'science'), 3),\n",
       " (('programming', 'skill'), 3),\n",
       " (('side', 'project'), 3),\n",
       " (('science', 'instructor'), 2),\n",
       " (('software', 'engineer'), 2),\n",
       " (('browser', 'support'), 2),\n",
       " (('support', 'video'), 2),\n",
       " (('video', 'tag'), 2),\n",
       " (('tag', 'suggest'), 2)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgs = [b for b in nltk.bigrams(cleaned_words)]\n",
    "fdist_bgs = nltk.FreqDist(bgs)\n",
    "fdist_bgs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('data', 'science', 'instructor'), 2),\n",
       " (('browser', 'support', 'video'), 2),\n",
       " (('support', 'video', 'tag'), 2),\n",
       " (('video', 'tag', 'suggest'), 2),\n",
       " (('tag', 'suggest', 'upgrade'), 2),\n",
       " (('suggest', 'upgrade', 'browser'), 2),\n",
       " (('python', 'swift', 'sql'), 2),\n",
       " (('enterprise', 'web', 'application'), 2),\n",
       " (('skill', 'enthusiastic', 'heart'), 2),\n",
       " (('knowledge', 'programming', 'skill'), 2)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgs = [b for b in nltk.trigrams(cleaned_words)]\n",
    "fdist_tgs = nltk.FreqDist(tgs)\n",
    "fdist_tgs.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mo', 'NNP'),\n",
       " ('Zhai', 'NNP'),\n",
       " ('|', 'NNP'),\n",
       " ('翟墨', 'NNP'),\n",
       " ('Mo', 'NNP'),\n",
       " ('Zhai', 'NNP'),\n",
       " ('Data', 'NNP'),\n",
       " ('Science', 'NNP'),\n",
       " ('Instructor', 'NNP'),\n",
       " ('Software', 'NNP')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.tags[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['mo zhai', '| 翟墨', 'mo zhai data', 'instructor software engineer', 'zhai @ uchicago.edu', 'mo', 'portfolio contact linkedin github twitter email résumé', 'mo crescat', 'scientia vita excolatur', 'loading coverr'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.noun_phrases[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence(\".NET\n",
      "[C#, ASP.NET, Entity Framework, Sql Server]\n",
      "Implemented variety web services (APIs) applications for mobile apps.\"), Sentence(\"Working on business web applicaion and side projects using MVC and Enitty Framowrk.\")]\n"
     ]
    }
   ],
   "source": [
    "b_sentences = blob.sentences\n",
    "print (b_sentences[24:26])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To process  cleaned-up version from NLTK we will have to convert text from nltk.text.Text to String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list = (cleaned_words[0:])\n",
    "words_string = ' '.join(words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mo', 'NN'),\n",
       " ('zhai', 'NN'),\n",
       " ('翟墨', 'NNP'),\n",
       " ('mo', 'NN'),\n",
       " ('zhai', 'NN'),\n",
       " ('data', 'NNS'),\n",
       " ('science', 'NN'),\n",
       " ('instructor', 'NN'),\n",
       " ('software', 'NN'),\n",
       " ('engineer', 'NN')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(words_string)\n",
    "blob.tags[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['mo', 'zhai', '翟墨', 'mo', 'zhai', 'data', 'science', 'instructor', 'software', 'engineer'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['mo', 'zhai']),\n",
       " WordList(['zhai', '翟墨']),\n",
       " WordList(['翟墨', 'mo']),\n",
       " WordList(['mo', 'zhai']),\n",
       " WordList(['zhai', 'data']),\n",
       " WordList(['data', 'science']),\n",
       " WordList(['science', 'instructor']),\n",
       " WordList(['instructor', 'software']),\n",
       " WordList(['software', 'engineer']),\n",
       " WordList(['engineer', 'zhai'])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.ngrams(2)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['mo', 'zhai', '翟墨']),\n",
       " WordList(['zhai', '翟墨', 'mo']),\n",
       " WordList(['翟墨', 'mo', 'zhai']),\n",
       " WordList(['mo', 'zhai', 'data']),\n",
       " WordList(['zhai', 'data', 'science']),\n",
       " WordList(['data', 'science', 'instructor']),\n",
       " WordList(['science', 'instructor', 'software']),\n",
       " WordList(['instructor', 'software', 'engineer']),\n",
       " WordList(['software', 'engineer', 'zhai']),\n",
       " WordList(['engineer', 'zhai', 'mo'])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.ngrams(3)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['mo', 'zhai', '翟墨', 'mo']),\n",
       " WordList(['zhai', '翟墨', 'mo', 'zhai']),\n",
       " WordList(['翟墨', 'mo', 'zhai', 'data']),\n",
       " WordList(['mo', 'zhai', 'data', 'science']),\n",
       " WordList(['zhai', 'data', 'science', 'instructor']),\n",
       " WordList(['data', 'science', 'instructor', 'software']),\n",
       " WordList(['science', 'instructor', 'software', 'engineer']),\n",
       " WordList(['instructor', 'software', 'engineer', 'zhai']),\n",
       " WordList(['software', 'engineer', 'zhai', 'mo']),\n",
       " WordList(['engineer', 'zhai', 'mo', 'portfolio'])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.ngrams(4)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Languages and Trslation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Simple es mejor que complejo\")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = TextBlob(\"Simple is better than complex\")\n",
    "b.translate(to=\"es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Simple vaut mieux que complexe\")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = TextBlob(\"Simple is better than complex\")\n",
    "b.translate(to=\"fr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOPWORDS - Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "document1 = TextBlob(raw)\n",
    "\n",
    "document2 = TextBlob(\"\"\"Python, from the Greek word (πύθων/πύθωνας), is a genus of\n",
    "nonvenomous pythons[2] found in Africa and Asia. Currently, 7 species are\n",
    "recognised.[2] A member of this genus, P. reticulatus, is among the longest\n",
    "snakes known.\"\"\")\n",
    "\n",
    "document3 = TextBlob(\"\"\"The Colt Python is a .357 Magnum caliber revolver formerly\n",
    "manufactured by Colt's Manufacturing Company of Hartford, Connecticut.\n",
    "It is sometimes referred to as a \"Combat Magnum\".[1] It was first introduced\n",
    "in 1955, the same year as Smith &amp; Wesson's M29 .44 Magnum. The now discontinued\n",
    "Colt Python targeted the premium revolver market segment. Some firearm\n",
    "collectors and writers such as Jeff Cooper, Ian V. Hogg, Chuck Hawks, Leroy\n",
    "Thompson, Renee Smeets and Martin Dougherty have described the Python as the\n",
    "finest production revolver ever made.\"\"\")\n",
    "\n",
    "bloblist = [document1, document2, document3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def tf(word, blob):\n",
    "    return blob.words.count(word) / len(blob.words)\n",
    "\n",
    "def n_containing(word, bloblist):\n",
    "    return sum(1 for blob in bloblist if word in blob.words)\n",
    "\n",
    "def idf(word, bloblist):\n",
    "    return math.log(len(bloblist) / (1 + n_containing(word, bloblist)))\n",
    "\n",
    "def tfidf(word, blob, bloblist):\n",
    "    return tf(word, blob) * idf(word, bloblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in document 1\n",
      "\tWord: I, TF-IDF: 0.00636\n",
      "\tWord: Development, TF-IDF: 0.00636\n",
      "\tWord: development, TF-IDF: 0.00636\n",
      "\tWord: C, TF-IDF: 0.00557\n",
      "\tWord: on, TF-IDF: 0.00557\n",
      "\tWord: Data, TF-IDF: 0.00477\n",
      "\tWord: data, TF-IDF: 0.00477\n",
      "\tWord: web, TF-IDF: 0.00477\n",
      "\tWord: skills, TF-IDF: 0.00477\n",
      "\tWord: for, TF-IDF: 0.00477\n",
      "\tWord: Game, TF-IDF: 0.00477\n",
      "\tWord: Skills, TF-IDF: 0.00477\n",
      "\tWord: Web, TF-IDF: 0.00477\n",
      "\tWord: game, TF-IDF: 0.00477\n",
      "\tWord: Mo, TF-IDF: 0.00398\n",
      "\tWord: Zhai, TF-IDF: 0.00398\n",
      "\tWord: Science, TF-IDF: 0.00398\n",
      "\tWord: Software, TF-IDF: 0.00398\n",
      "\tWord: zhai, TF-IDF: 0.00398\n",
      "\tWord: solid, TF-IDF: 0.00398\n",
      "Top words in document 2\n",
      "\tWord: genus, TF-IDF: 0.02192\n",
      "\tWord: 2, TF-IDF: 0.02192\n",
      "\tWord: A, TF-IDF: 0.02192\n",
      "\tWord: Greek, TF-IDF: 0.01096\n",
      "\tWord: word, TF-IDF: 0.01096\n",
      "\tWord: πύθων/πύθωνας, TF-IDF: 0.01096\n",
      "\tWord: nonvenomous, TF-IDF: 0.01096\n",
      "\tWord: pythons, TF-IDF: 0.01096\n",
      "\tWord: found, TF-IDF: 0.01096\n",
      "\tWord: Africa, TF-IDF: 0.01096\n",
      "\tWord: Asia, TF-IDF: 0.01096\n",
      "\tWord: Currently, TF-IDF: 0.01096\n",
      "\tWord: 7, TF-IDF: 0.01096\n",
      "\tWord: species, TF-IDF: 0.01096\n",
      "\tWord: are, TF-IDF: 0.01096\n",
      "\tWord: recognised, TF-IDF: 0.01096\n",
      "\tWord: member, TF-IDF: 0.01096\n",
      "\tWord: this, TF-IDF: 0.01096\n",
      "\tWord: P, TF-IDF: 0.01096\n",
      "\tWord: reticulatus, TF-IDF: 0.01096\n",
      "Top words in document 3\n",
      "\tWord: The, TF-IDF: 0.02733\n",
      "\tWord: as, TF-IDF: 0.01822\n",
      "\tWord: Colt, TF-IDF: 0.01367\n",
      "\tWord: Magnum, TF-IDF: 0.01367\n",
      "\tWord: revolver, TF-IDF: 0.01367\n",
      "\tWord: 's, TF-IDF: 0.00911\n",
      "\tWord: It, TF-IDF: 0.00911\n",
      "\tWord: 357, TF-IDF: 0.00456\n",
      "\tWord: caliber, TF-IDF: 0.00456\n",
      "\tWord: formerly, TF-IDF: 0.00456\n",
      "\tWord: manufactured, TF-IDF: 0.00456\n",
      "\tWord: Manufacturing, TF-IDF: 0.00456\n",
      "\tWord: Company, TF-IDF: 0.00456\n",
      "\tWord: Hartford, TF-IDF: 0.00456\n",
      "\tWord: Connecticut, TF-IDF: 0.00456\n",
      "\tWord: sometimes, TF-IDF: 0.00456\n",
      "\tWord: referred, TF-IDF: 0.00456\n",
      "\tWord: Combat, TF-IDF: 0.00456\n",
      "\tWord: 1, TF-IDF: 0.00456\n",
      "\tWord: was, TF-IDF: 0.00456\n"
     ]
    }
   ],
   "source": [
    "for i, blob in enumerate(bloblist):\n",
    "    print(\"Top words in document {}\".format(i + 1))\n",
    "    scores = {word: tfidf(word, blob, bloblist) for word in blob.words}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:20]:\n",
    "        print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
