{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('popular', halt_on_error=False)\n",
    "#nltk.download('all', halt_on_error=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "#import nltk as nltk\n",
    "#import nltk.corpus  \n",
    "#from nltk.text import Text\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis with TextBlob: Polarity and Subjectivity\n",
    "Subjectivity can come in many forms, e.g., opinions, allegations, desires, beliefs, suspicions, and speculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__textblob.sentiments__ module contains two sentiment analysis implementations, PatternAnalyzer (based on the pattern library: https://www.clips.uantwerpen.be/pattern) and NaiveBayesAnalyzer (an NLTK classifier trained on a movie reviews corpus).\n",
    "\n",
    "The default implementation is PatternAnalyzer, but you can override the analyzer to use NaiveBayesAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Tim is ugly.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(classification='neg', p_pos=0.3818562132011153, p_neg=0.6181437867988844)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(text, analyzer=NaiveBayesAnalyzer())\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.475, subjectivity=0.8)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(text)\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"Wolf experts urge UK police not to shoot escaped animal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(classification='pos', p_pos=0.6175593484868018, p_neg=0.382440651513196)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(text, analyzer=NaiveBayesAnalyzer())\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.0, subjectivity=0.0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(text)\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"A 29-year-old man was shot Friday evening on the South Side.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(classification='pos', p_pos=0.7079960513228761, p_neg=0.2920039486771243)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(text, analyzer=NaiveBayesAnalyzer())\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.0, subjectivity=0.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(text)\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Three teenagers have been charged with felony robbery after they were\\\n",
    "taken into custody in connection with a string of robberies from the Near North Side to Kenwood.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(classification='pos', p_pos=0.895182524022347, p_neg=0.1048174759776575)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(text, analyzer=NaiveBayesAnalyzer())\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.1, subjectivity=0.4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(text)\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"American and Southwest joined United Airlines in reporting expectation-beating earnings \\\n",
    "and unveiling expansion plans.  But investors, fearing that more flights might lead to a fare war, \\\n",
    "pounded airline stocks for a second day even as American Airlines signaled that higher fuel costs \\\n",
    "will probably force it to raise fares..\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(classification='pos', p_pos=0.9141571646860674, p_neg=0.0858428353139356)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(text, analyzer=NaiveBayesAnalyzer())\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.15, subjectivity=0.2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(text)\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" The gorgeous Giulia Quadrifoglio seduces the soul and sears the \\\n",
    "senses with a beautiful balance of aggression and finesse. \\\n",
    "Alfa flaunts its racing pedigree with the four-leaf-clover \\\n",
    "badge displayed on the Giulia’s shapely flanks. \\\n",
    "Its Ferrari-derived twin-turbo V-6 sings a sinister tune, \\\n",
    "belting out 505 horsepower. Its clever, communicative chassis can \\\n",
    "conquer a race course with unfiltered ferocity or coolly traverse \\\n",
    "the tarmac without commotion. An excellent eight-speed automatic \\\n",
    "transmission and rear-wheel drive are standard; sadly, \\\n",
    "a manual gearbox is missing. Alfa Romeo’s past and present \\\n",
    "reliability issues also remain an unknown quantity. \\\n",
    "Still, the Giulia Quadrifoglio, or QF, is an exotic sports sedan \\\n",
    "that sets a new benchmark for the genre—which is why it made our list of 10Best Cars for 2018. .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(classification='pos', p_pos=0.991948748693045, p_neg=0.008051251306939424)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(text, analyzer=NaiveBayesAnalyzer())\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.15378787878787878, subjectivity=0.6241341991341992)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(text)\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"My husband ordered a fruit arrangement for me for Valentine's Day. \\\n",
    "He had planned on taking me to the movies with two free tickets he was promised with a \\\n",
    "promotion you had been advertising. My husband was unaware that these tickets came via email. \\\n",
    "However, your sales representative who took his order failed to record his email address. \\\n",
    "Therefore we never received the tickets. \\\n",
    "I have called corporate and the store manager about this. \\\n",
    "They seem to not be able to resolve things in a timely manner. \\\n",
    "Also the fruit was not the best tasting. \\\n",
    "Needless to say we will never be supporting your business again. \\\n",
    "Overall poor customer service and a very overpriced product.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(classification='pos', p_pos=0.9993862773779272, p_neg=0.0006137226220642661)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(text, analyzer=NaiveBayesAnalyzer())\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.08636363636363636, subjectivity=0.425)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(text)\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading from URL\n",
    "#### BeautifulSoup to clean up meta-tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/University_of_Chicago\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "page = urllib.request.urlopen(url)\n",
    "soup = BeautifulSoup(page.read(), \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nkings.[9][10][11][12]\n",
      "The university is composed of the College, various graduate programs and interdisciplinary committees organized into five academic research divisions and seven professional schools. Beyond the arts and sciences, Chicago is also well known for its professional schools, which include the Pritzker School of Medicine, the Booth School of Business, the Law School, the School of Social Service Administration, the Harris School of Public Policy Studies, the Divinity School and the Graham School of Continuing Liberal and Professional Studies. The university currently enrolls 5,971 undergraduate students, and 16,016 students overall.[13]\n",
      "University of Chicago scholars have played a major role in the development of many academic disciplines, including sociology,[14] law,[15] economics,[16] literary criticism,[17] re\n"
     ]
    }
   ],
   "source": [
    "uc_wiki = (soup.get_text())\n",
    "#print (type(uc_wiki))\n",
    "print (uc_wiki[7170:8010]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(uc_wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment analysis on entire body of text might be difficult to interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.08580098320482935, subjectivity=0.36561234951767513)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence(\"[21]  With an estimated completion date of 2021, the Barack Obama Presidential Center will be housed at the university and include both the Obama presidential library and offices of the Obama Foundation.\"), Sentence(\"[22]\n",
      "The University of Chicago has many prominent alumni, faculty members and researchers.\"), Sentence(\"97 Nobel laureates[23] have been affiliated with the university as professors, students, faculty, or staff, making it a university with one of the highest concentrations of Nobel laureates in the world.\"), Sentence(\"Similarly, 34 faculty members and 17 alumni have been awarded the MacArthur \"Genius Grant\".\"), Sentence(\"[24] In addition, Chicago's alumni and faculty include 53 Rhodes Scholars,[25] 25 Marshall Scholars,[26] 9 Fields Medalists,[27] 4 Turing Award Winners, 24 Pulitzer Prize winners,[28] 20 National Humanities Medalists,[29] 16 billionaire graduates and a plethora of members of the United States Congress and heads of state of countries all over the world.\")]\n"
     ]
    }
   ],
   "source": [
    "b_sentences = blob.sentences\n",
    "print (b_sentences[10:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_sentiment = []\n",
    "b_subjectivity = []\n",
    "for sentence in blob.sentences:\n",
    "    b_sentiment.append(str(sentence.sentiment.polarity))\n",
    "    b_subjectivity.append(str(sentence.sentiment.subjectivity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_sen_sen = list(zip(b_sentences, b_sentiment, b_subjectivity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Sentence(\"Stagg is the namesake of the university's Stagg Field.\"), '0.0', '0.0')\n",
      "\n",
      "(Sentence(\"[43]\n",
      "The business school was founded thereafter in 1898[44] and the law school was founded in 1902.\"), '0.0', '0.0')\n",
      "\n",
      "(Sentence(\"[45] Harper died in 1906[46] and was replaced by a succession of three presidents whose tenures lasted until 1929.\"), '0.0', '0.0')\n",
      "\n",
      "(Sentence(\"[47] During this period, the Oriental Institute was founded to support and interpret archeological work in what was then called the Near East.\"), '0.1', '0.4')\n",
      "\n",
      "(Sentence(\"[48]\n",
      "In the 1890s, the University of Chicago, fearful that its vast resources would injure smaller schools by drawing away good students, affiliated with several regional colleges and universities: Des Moines College, Kalamazoo College, Butler University, and Stetson University.\"), '-0.040000000000000015', '0.62')\n"
     ]
    }
   ],
   "source": [
    "print(*b_sen_sen[35:40], sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing sentiment for entire book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory = './data/'\n",
    "book = 'book_2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/book_2.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-ef524bb8e9cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mblob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/book_2.txt'"
     ]
    }
   ],
   "source": [
    "blob = TextBlob(open(directory+book, encoding=\"utf8\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "type(blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the sentiment of each sentence in the book and passing to PandasDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "polarity = []\n",
    "subjectivity = []\n",
    "sentences = []\n",
    "sentiment_df = pd.DataFrame(columns=['sentence', 'polarity', 'subjectivity'])\n",
    "\n",
    "for sentence in blob.sentences:\n",
    "    polarity.append(sentence.sentiment.polarity)\n",
    "    subjectivity.append(sentence.sentiment.subjectivity)\n",
    "    sentences.append(str(sentence.raw))\n",
    "\n",
    "sentiment_df['sentence'] = sentences\n",
    "sentiment_df['polarity'] = polarity\n",
    "sentiment_df['subjectivity'] = subjectivity\n",
    "\n",
    "sentiment_df['sentence'] = sentiment_df['sentence'].str.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "polarity = []\n",
    "subjectivity = []\n",
    "sentences = []\n",
    "sentiment_df = pd.DataFrame(columns=['sentence', 'polarity', 'subjectivity'])\n",
    "\n",
    "for sentence in blob.sentences:\n",
    "    polarity.append(sentence.sentiment.polarity)\n",
    "    subjectivity.append(sentence.sentiment.subjectivity)\n",
    "    sentences.append(str(sentence.raw))\n",
    "\n",
    "sentiment_df['sentence'] = sentences\n",
    "sentiment_df['polarity'] = polarity\n",
    "sentiment_df['subjectivity'] = subjectivity\n",
    "\n",
    "sentiment_df['sentence'] = sentiment_df['sentence'].str.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most positive sentences in the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df.sort_values(by='polarity', ascending=False, inplace=True)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "sentiment_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most negative sentences in the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df.sort_values(by='polarity', ascending=True, inplace=True)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "sentiment_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiment_df.sort_index(inplace=True)\n",
    "sentiment_top_df = sentiment_df.head(n=200)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "#sentiment_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting sentiment changes in the book as the story unveils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure().set_size_inches(20, 10)\n",
    "plt.plot(sentiment_top_df['polarity'])\n",
    "plt.xlabel('Sentence')\n",
    "plt.ylabel('Polarity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Tweets with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory = './data/'\n",
    "file = 'jeep_new.txt'\n",
    "path = directory + file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(path,sep='\\t', names = ['id', 'lang', 'created_at', 'screen_name', \\\n",
    "                                                       'name', 'location', 'retweet_count', 'text'])\n",
    "\n",
    "tweets = tweets.sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['lang'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter non-English tweets\n",
    "tweets_eng = tweets[tweets['lang']=='en'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_eng.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count records \n",
    "len(tweets_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove special characters to avoid problems with analysis\n",
    "tweets_eng['text_clean'] = tweets_eng['text'].map(lambda x: re.sub('[^a-zA-Z0-9 @ . , : - _]', '', str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100)\n",
    "tweets_eng[['text', 'text_clean']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blob = TextBlob(tweets_eng['text_clean'].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags = TextBlob(tweets_eng['text_clean'].to_string()).tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list all possible tags and values\n",
    "#nltk.help.upenn_tagset('.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 50)\n",
    "tags_pd = pd.DataFrame(tags, columns={\"Word\",\"POS Tag\"})\n",
    "tags_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nouns = TextBlob(tweets_eng['text_clean'].to_string()).noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100)\n",
    "# The x in the lambda function is a row (because axis=1 is set)\n",
    "# Apply iterates the function accross the dataframe's rows\n",
    "tweets_eng['nouns'] = tweets_eng.apply(lambda x: TextBlob(x['text_clean']).noun_phrases, axis=1)\n",
    "tweets_eng[['nouns']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_eng['polarity'] = tweets_eng.apply(lambda x: TextBlob(x['text_clean']).sentiment.polarity, axis=1)\n",
    "tweets_eng['subjectivity'] = tweets_eng.apply(lambda x: TextBlob(x['text_clean']).sentiment.subjectivity, axis=1)\n",
    "tweets_eng[['text_clean', 'polarity', 'subjectivity']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_eng[['text_clean', 'polarity', 'subjectivity']][tweets_eng['polarity'] > 0.6].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_eng[['text_clean', 'polarity', 'subjectivity']][tweets_eng['polarity'] < -0.6].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Very advanced (and labor intensive) sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the corpus of positive/negative words compiled by University of Pittsburgh, available at UNC Chapel Hill websie\n",
    "# These came from researchers Theresa Wilson, Janyce Wiebe, and Paul Hoffmann at the University of Pittsburgh, \n",
    "# and were readily available at http://mpqa.cs.pitt.edu/\n",
    "\n",
    "#Code adopted from: http://nealcaren.web.unc.edu/an-introduction-to-text-analysis-with-python-part-3/\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import urllib\n",
    "outpath = 'http://www.unc.edu/~ncaren/haphazard/'\n",
    "directory = 'C://Users//Nick//Documents//Teaching//Data Projects//Text//Tweets//'\n",
    "tweet_directory = 'C://Users//Nick//Documents//Teaching//Data Projects//Text//Tweets//'\n",
    "file_pos = 'positive.txt'\n",
    "file_neg = 'negative.txt'\n",
    "\n",
    "corpus = [file_pos,file_neg]\n",
    "for file in corpus:\n",
    "    urlretrieve(outpath+file,tweet_directory+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_list = tweets_eng['text_clean'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_sent = open(tweet_directory +file_pos).read()\n",
    "pos_words = pos_sent.split('\\n')\n",
    "neg_sent = open(tweet_directory +file_neg).read()\n",
    "neg_words = neg_sent.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# customize the dictionaries by adding and removing your own positive and negative words and get some counts\n",
    "\n",
    "pos_add = ['your_pos_term_1, your_pos_term_2']\n",
    "\n",
    "for term in pos_add:\n",
    "    pos_words.append(term)\n",
    "\n",
    "neg_add = ['your_neg_term_1, your_neg_term_2']\n",
    "\n",
    "for term in neg_add:\n",
    "    neg_words.append(term)\n",
    "\n",
    "import re\n",
    "from string import punctuation\n",
    "from __future__ import division  \n",
    "sentiment_scores=[]\n",
    "for tweet in tweet_list:\n",
    "    sentiment_score=0\n",
    "    for p in list(punctuation):\n",
    "        tweet=tweet.replace(p,'')\n",
    "        words=tweet.split(' ')\n",
    "    for word in words:\n",
    "        if word in pos_words:\n",
    "            sentiment_score=sentiment_score+1\n",
    "        if word in neg_words:\n",
    "            sentiment_score=sentiment_score-1\n",
    "    sentiment_scores.append(sentiment_score/len(words))\n",
    "\n",
    "tweet_sentiment=zip(tweet_list,sentiment_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a dataframe from the results\n",
    "column_names = [\"Text\", \"Sentiment_Score\"]\n",
    "sentiment_results = [tweet_list, sentiment_scores]\n",
    "results_dict = dict(zip(column_names,sentiment_results))\n",
    "all_tweets_df = pd.DataFrame.from_dict(results_dict, orient='columns')\n",
    "all_tweets_df = all_tweets_df[column_names]   # set specific column order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list to store the sentiments\n",
    "sent_list = []\n",
    "\n",
    "# For each row in the column,\n",
    "for row in all_tweets_df['Sentiment_Score']:\n",
    "    if row > 0:\n",
    "        sent_list.append('Positive')\n",
    "    elif row < 0:\n",
    "        sent_list.append('Negative')\n",
    "    else:\n",
    "        sent_list.append('Neutral')\n",
    "\n",
    "# Create a column from the list\n",
    "all_tweets_df['Sentiment_Label'] = sent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure I didn't loose any records\n",
    "len(tweet_list) - len(all_tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets_df.sample(frac=0.005, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all_tweets_df['Sentiment_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure().set_size_inches(10, 5)\n",
    "\n",
    "CountSentiment = pd.value_counts(all_tweets_df['Sentiment_Label'].values, sort=True)\n",
    "print (CountSentiment)\n",
    "\n",
    "#CountStatus.plot.barh()\n",
    "CountSentiment.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export the results of advanced sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(tweet_directory+'jeep_adv_sentiment.xlsx', engine='xlsxwriter')\n",
    "all_tweets_df.to_excel(writer, sheet_name='Tweets_Sentiment')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nteract": {
   "version": "0.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
